{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import clearml\n",
    "\n",
    "clearml.browser_login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T07:27:05.608269Z",
     "start_time": "2024-05-22T07:27:04.160806Z"
    }
   },
   "id": "dcf27152f9c36d07",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train36, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train36\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=689837a4f7244a7bb87d6425f738aa13\r\n",
      "2024-05-22 11:10:56,107 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/689837a4f7244a7bb87d6425f738aa13/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train36', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train36/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train36\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.081      1.117      1.142         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.636      0.579       0.66      0.521\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G      1.059      1.031      1.124         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.534      0.615      0.648      0.515\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.073      1.068      1.122        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.699      0.534      0.642      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.047      0.942      1.145         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.707      0.517      0.645      0.503\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.9933     0.9576      1.084         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.734      0.508      0.643      0.505\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G     0.9892     0.9058      1.094         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.744      0.493      0.636      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G     0.9773     0.8787       1.07        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.701      0.528      0.637      0.498\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9586     0.8698      1.058        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.751      0.509      0.625      0.487\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G      1.007     0.8701      1.105        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.733      0.511       0.62      0.485\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G     0.9666      0.823      1.059        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.767      0.492      0.616      0.481\r\n",
      "\r\n",
      "10 epochs completed in 0.383 hours.\r\n",
      "Optimizer stripped from runs/detect/train36/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train36/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train36/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.637       0.58       0.66      0.521\r\n",
      "                person         41         99      0.702      0.747      0.846      0.641\r\n",
      "               bicycle         41          2      0.414        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.722      0.588      0.632      0.378\r\n",
      "            motorcycle         41          1      0.789          1      0.995      0.895\r\n",
      "                   bus         41          2      0.609          1      0.995      0.945\r\n",
      "                 train         41          2      0.402        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.623      0.334      0.531      0.359\r\n",
      "         traffic light         41          8      0.435      0.109      0.259     0.0597\r\n",
      "             stop sign         41          1      0.625          1      0.995      0.895\r\n",
      "                 bench         41          7      0.638      0.429      0.531      0.294\r\n",
      "                  bird         41         20      0.775       0.25      0.341      0.253\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.793       0.84      0.586\r\n",
      "                   cow         41          9      0.732      0.556      0.815      0.632\r\n",
      "                 zebra         41          5      0.781        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.718      0.444      0.701      0.564\r\n",
      "               handbag         41          1       0.72          1      0.995      0.895\r\n",
      "                  kite         41          1      0.635          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.643          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.684      0.735      0.913      0.633\r\n",
      "             surfboard         41          2       0.37      0.609      0.745      0.597\r\n",
      "         tennis racket         41          5      0.794      0.778       0.88      0.682\r\n",
      "                   cup         41          2       0.22          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.641          1      0.995       0.82\r\n",
      "              sandwich         41          4          1      0.708      0.856      0.657\r\n",
      "              broccoli         41         12       0.26       0.25      0.201      0.135\r\n",
      "                carrot         41         13      0.425      0.119      0.174      0.106\r\n",
      "                 pizza         41         13          1      0.242      0.684      0.383\r\n",
      "                 chair         41         12      0.691      0.667      0.665      0.528\r\n",
      "                 couch         41          1      0.622          1      0.995      0.995\r\n",
      "          dining table         41          7      0.507      0.714      0.565      0.356\r\n",
      "                    tv         41          1      0.323          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.393      0.143     0.0989     0.0455\r\n",
      "                  book         41         38      0.622      0.433      0.475      0.271\r\n",
      "                 clock         41          3      0.568      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.784          1      0.945      0.786\r\n",
      "            toothbrush         41          2      0.439      0.439      0.306      0.266\r\n",
      "Speed: 1.3ms preprocess, 326.5ms inference, 0.0ms loss, 1.5ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train36\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T08:39:30.725028Z",
     "start_time": "2024-05-22T08:10:47.124638Z"
    }
   },
   "id": "7f51e94a9571e1c6",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train37, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train37\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=10c492716a9b4875b2d0e4f0f8661c5a\r\n",
      "2024-05-22 11:39:41,067 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/10c492716a9b4875b2d0e4f0f8661c5a/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train37', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train37/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train37\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.081      1.117      1.142         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.636      0.579       0.66      0.521\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G      1.059      1.031      1.124         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.534      0.615      0.648      0.515\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.073      1.068      1.122        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.699      0.534      0.642      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.047      0.942      1.145         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.707      0.517      0.645      0.503\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.9934     0.9576      1.084         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.734      0.508      0.643      0.504\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G     0.9891      0.906      1.094         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.743      0.493      0.636      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G     0.9776     0.8787      1.071        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.702      0.528      0.637      0.497\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9583     0.8704      1.058        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.751      0.509      0.625      0.487\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G      1.007       0.87      1.104        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.733      0.511       0.62      0.486\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G      0.966     0.8232      1.059        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.768      0.492      0.618      0.486\r\n",
      "\r\n",
      "10 epochs completed in 0.417 hours.\r\n",
      "Optimizer stripped from runs/detect/train37/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train37/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train37/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.637       0.58       0.66      0.521\r\n",
      "                person         41         99      0.702      0.747      0.846      0.641\r\n",
      "               bicycle         41          2      0.414        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.722      0.588      0.632      0.378\r\n",
      "            motorcycle         41          1      0.789          1      0.995      0.895\r\n",
      "                   bus         41          2      0.609          1      0.995      0.945\r\n",
      "                 train         41          2      0.402        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.623      0.334      0.531      0.359\r\n",
      "         traffic light         41          8      0.435      0.109      0.259     0.0597\r\n",
      "             stop sign         41          1      0.625          1      0.995      0.895\r\n",
      "                 bench         41          7      0.638      0.429      0.531      0.294\r\n",
      "                  bird         41         20      0.775       0.25      0.341      0.253\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.793       0.84      0.586\r\n",
      "                   cow         41          9      0.732      0.556      0.815      0.632\r\n",
      "                 zebra         41          5      0.781        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.718      0.444      0.701      0.564\r\n",
      "               handbag         41          1       0.72          1      0.995      0.895\r\n",
      "                  kite         41          1      0.635          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.643          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.684      0.735      0.913      0.633\r\n",
      "             surfboard         41          2       0.37      0.609      0.745      0.597\r\n",
      "         tennis racket         41          5      0.794      0.778       0.88      0.682\r\n",
      "                   cup         41          2       0.22          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.641          1      0.995       0.82\r\n",
      "              sandwich         41          4          1      0.708      0.856      0.657\r\n",
      "              broccoli         41         12       0.26       0.25      0.201      0.135\r\n",
      "                carrot         41         13      0.425      0.119      0.174      0.106\r\n",
      "                 pizza         41         13          1      0.242      0.684      0.383\r\n",
      "                 chair         41         12      0.691      0.667      0.665      0.528\r\n",
      "                 couch         41          1      0.622          1      0.995      0.995\r\n",
      "          dining table         41          7      0.507      0.714      0.565      0.356\r\n",
      "                    tv         41          1      0.323          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.393      0.143     0.0989     0.0455\r\n",
      "                  book         41         38      0.622      0.433      0.475      0.271\r\n",
      "                 clock         41          3      0.568      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.785          1      0.945      0.786\r\n",
      "            toothbrush         41          2      0.439      0.439      0.306      0.266\r\n",
      "Speed: 1.4ms preprocess, 334.7ms inference, 0.0ms loss, 1.2ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train37\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --weight_decay 0.005"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T09:05:26.304664Z",
     "start_time": "2024-05-22T08:39:30.729612Z"
    }
   },
   "id": "42157cde6d91bee7",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train38, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.05, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train38\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=762674a7027f4519a569f5145a4d6f19\r\n",
      "2024-05-22 12:05:36,076 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/762674a7027f4519a569f5145a4d6f19/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train38', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train38/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.05), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train38\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.081      1.117      1.142         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.636      0.579       0.66      0.521\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G      1.059      1.031      1.124         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.534      0.615      0.648      0.515\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.073      1.068      1.122        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.699      0.534      0.642      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.047      0.942      1.145         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.707      0.517      0.645      0.503\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.9933     0.9576      1.084         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.734      0.508      0.643      0.505\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G     0.9891     0.9058      1.094         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.745      0.492      0.635      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G     0.9772     0.8786       1.07        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.701      0.528      0.637      0.498\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9583     0.8693      1.058        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.752      0.509      0.623      0.486\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G      1.007     0.8701      1.105        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.764      0.497      0.618      0.482\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G     0.9648      0.822      1.058        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.764      0.495      0.617      0.482\r\n",
      "\r\n",
      "10 epochs completed in 0.383 hours.\r\n",
      "Optimizer stripped from runs/detect/train38/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train38/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train38/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.637       0.58       0.66      0.521\r\n",
      "                person         41         99      0.702      0.747      0.846      0.641\r\n",
      "               bicycle         41          2      0.414        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.722      0.588      0.632      0.378\r\n",
      "            motorcycle         41          1      0.789          1      0.995      0.895\r\n",
      "                   bus         41          2      0.609          1      0.995      0.945\r\n",
      "                 train         41          2      0.402        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.622      0.334      0.531      0.359\r\n",
      "         traffic light         41          8      0.435      0.109      0.259     0.0597\r\n",
      "             stop sign         41          1      0.625          1      0.995      0.895\r\n",
      "                 bench         41          7      0.638      0.429      0.531      0.294\r\n",
      "                  bird         41         20      0.775       0.25      0.341      0.253\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.793       0.84      0.586\r\n",
      "                   cow         41          9      0.732      0.556      0.815      0.632\r\n",
      "                 zebra         41          5      0.781        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.719      0.444      0.701      0.564\r\n",
      "               handbag         41          1       0.72          1      0.995      0.895\r\n",
      "                  kite         41          1      0.635          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.643          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.684      0.734      0.913      0.633\r\n",
      "             surfboard         41          2       0.37      0.609      0.745      0.597\r\n",
      "         tennis racket         41          5      0.794      0.778       0.88      0.682\r\n",
      "                   cup         41          2       0.22          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.641          1      0.995       0.82\r\n",
      "              sandwich         41          4          1      0.708      0.856      0.657\r\n",
      "              broccoli         41         12       0.26       0.25      0.201      0.135\r\n",
      "                carrot         41         13      0.425      0.119      0.174      0.106\r\n",
      "                 pizza         41         13          1      0.242      0.684      0.383\r\n",
      "                 chair         41         12      0.691      0.667      0.665      0.528\r\n",
      "                 couch         41          1      0.622          1      0.995      0.995\r\n",
      "          dining table         41          7      0.507      0.714      0.565      0.356\r\n",
      "                    tv         41          1      0.323          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.393      0.143     0.0989     0.0454\r\n",
      "                  book         41         38      0.622      0.433      0.475      0.271\r\n",
      "                 clock         41          3      0.568      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.784          1      0.945      0.786\r\n",
      "            toothbrush         41          2      0.439      0.439      0.306      0.266\r\n",
      "Speed: 1.2ms preprocess, 389.5ms inference, 0.0ms loss, 1.2ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train38\u001B[0m\r\n",
      "Skipping upload, could not find object file '/var/folders/jr/7cpxm2sj4y74r__lw8nqpvfw0000gn/T/tmpizaue0zq.png'\r\n",
      "Skipping upload, could not find object file '/var/folders/jr/7cpxm2sj4y74r__lw8nqpvfw0000gn/T/tmp99n6w75q.png'\r\n",
      "Skipping upload, could not find object file '/var/folders/jr/7cpxm2sj4y74r__lw8nqpvfw0000gn/T/tmpahykg4um.png'\r\n",
      "Skipping upload, could not find object file '/var/folders/jr/7cpxm2sj4y74r__lw8nqpvfw0000gn/T/tmpetwz3vmb.png'\r\n",
      "Skipping upload, could not find object file '/var/folders/jr/7cpxm2sj4y74r__lw8nqpvfw0000gn/T/tmpqb6g98bd.png'\r\n",
      "Skipping upload, could not find object file '/var/folders/jr/7cpxm2sj4y74r__lw8nqpvfw0000gn/T/tmpzn54l7t1.png'\r\n",
      "Skipping upload, could not find object file '/var/folders/jr/7cpxm2sj4y74r__lw8nqpvfw0000gn/T/tmp4z_28lqu.png'\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --weight_decay 0.05"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T09:29:51.571628Z",
     "start_time": "2024-05-22T09:05:26.301854Z"
    }
   },
   "id": "a9c420ad8682ad21",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train39, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.5, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train39\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=5a4bdbeb87ed41468f76e7807c5a3a7c\r\n",
      "2024-05-22 12:30:01,560 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/5a4bdbeb87ed41468f76e7807c5a3a7c/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train39', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train39/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.5), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train39\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.081      1.117      1.142         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.639      0.576       0.66       0.52\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G      1.059      1.031      1.124         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.534      0.615      0.648      0.515\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.073      1.068      1.122        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.691      0.537      0.643      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.047      0.942      1.145         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.707      0.518      0.647      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.9932     0.9578      1.084         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.734      0.508      0.643      0.504\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G     0.9891     0.9058      1.094         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.744      0.493      0.636      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G     0.9774     0.8785       1.07        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356        0.7      0.528      0.637      0.498\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9594     0.8696      1.059        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.752      0.508      0.625      0.488\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G      1.007     0.8702      1.104        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.735       0.51      0.618      0.486\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G     0.9658      0.822      1.059        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.767      0.494      0.618      0.486\r\n",
      "\r\n",
      "10 epochs completed in 0.429 hours.\r\n",
      "Optimizer stripped from runs/detect/train39/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train39/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train39/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.637       0.58       0.66      0.521\r\n",
      "                person         41         99      0.702      0.747      0.846      0.641\r\n",
      "               bicycle         41          2      0.413        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.721      0.588      0.632      0.378\r\n",
      "            motorcycle         41          1      0.788          1      0.995      0.895\r\n",
      "                   bus         41          2      0.609          1      0.995      0.945\r\n",
      "                 train         41          2      0.401        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.626       0.34      0.531      0.359\r\n",
      "         traffic light         41          8      0.436      0.109      0.259     0.0597\r\n",
      "             stop sign         41          1      0.624          1      0.995      0.895\r\n",
      "                 bench         41          7      0.635      0.429      0.531      0.294\r\n",
      "                  bird         41         20      0.774       0.25      0.341      0.253\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.793       0.84      0.586\r\n",
      "                   cow         41          9      0.731      0.556      0.815      0.632\r\n",
      "                 zebra         41          5      0.781        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.714      0.444      0.701      0.565\r\n",
      "               handbag         41          1      0.719          1      0.995      0.895\r\n",
      "                  kite         41          1      0.634          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.643          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.684      0.735      0.913      0.633\r\n",
      "             surfboard         41          2       0.37      0.611      0.745      0.597\r\n",
      "         tennis racket         41          5      0.795      0.778       0.88      0.682\r\n",
      "                   cup         41          2       0.22          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3       0.64          1      0.995       0.82\r\n",
      "              sandwich         41          4          1      0.708      0.856      0.657\r\n",
      "              broccoli         41         12      0.259       0.25      0.201      0.135\r\n",
      "                carrot         41         13      0.426       0.12      0.173      0.106\r\n",
      "                 pizza         41         13          1      0.244      0.684      0.383\r\n",
      "                 chair         41         12       0.69      0.667      0.665      0.528\r\n",
      "                 couch         41          1      0.622          1      0.995      0.995\r\n",
      "          dining table         41          7      0.507      0.714      0.565      0.356\r\n",
      "                    tv         41          1      0.323          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.393      0.143     0.0989     0.0455\r\n",
      "                  book         41         38      0.628      0.445      0.475      0.271\r\n",
      "                 clock         41          3      0.566      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.783          1      0.945      0.786\r\n",
      "            toothbrush         41          2       0.44       0.44      0.306      0.266\r\n",
      "Speed: 1.2ms preprocess, 379.7ms inference, 0.0ms loss, 2.0ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train39\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --weight_decay 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T09:56:43.350218Z",
     "start_time": "2024-05-22T09:29:51.581596Z"
    }
   },
   "id": "4bbf31934221913f",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train47, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.9, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train47\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=1afec77f4f7f4ea78e425674a2db3be1\r\n",
      "2024-05-22 13:42:40,985 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/1afec77f4f7f4ea78e425674a2db3be1/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train47', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train47/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.9), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train47\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.081      1.117      1.142         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.639      0.576       0.66       0.52\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G      1.059      1.031      1.124         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.534      0.613      0.648      0.515\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.073      1.068      1.122        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.69      0.537      0.643      0.507\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.047      0.942      1.145         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.705       0.52      0.648      0.505\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.9934     0.9576      1.084         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.733      0.508      0.645      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G     0.9891      0.906      1.094         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.744      0.493      0.636      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G     0.9775     0.8788      1.071        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.701      0.528      0.638      0.498\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9584     0.8704      1.059        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.75      0.509      0.626      0.488\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G      1.007     0.8703      1.104        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.735       0.51      0.618      0.485\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G     0.9666     0.8231      1.059        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.768      0.492      0.618      0.486\r\n",
      "\r\n",
      "10 epochs completed in 0.484 hours.\r\n",
      "Optimizer stripped from runs/detect/train47/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train47/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train47/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.636       0.58       0.66      0.521\r\n",
      "                person         41         99      0.702      0.747      0.846      0.641\r\n",
      "               bicycle         41          2      0.413        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.722      0.588      0.632      0.378\r\n",
      "            motorcycle         41          1      0.788          1      0.995      0.895\r\n",
      "                   bus         41          2      0.609          1      0.995      0.945\r\n",
      "                 train         41          2      0.401        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.627      0.341      0.531      0.359\r\n",
      "         traffic light         41          8      0.436      0.109      0.259     0.0596\r\n",
      "             stop sign         41          1      0.624          1      0.995      0.895\r\n",
      "                 bench         41          7      0.635      0.429      0.531      0.294\r\n",
      "                  bird         41         20      0.774       0.25      0.341      0.253\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.793       0.84      0.586\r\n",
      "                   cow         41          9      0.731      0.556      0.815      0.632\r\n",
      "                 zebra         41          5      0.781        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.716      0.444      0.701      0.565\r\n",
      "               handbag         41          1      0.718          1      0.995      0.895\r\n",
      "                  kite         41          1      0.634          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.643          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.683      0.734      0.913      0.633\r\n",
      "             surfboard         41          2       0.37      0.611      0.745      0.597\r\n",
      "         tennis racket         41          5      0.795      0.778       0.88      0.682\r\n",
      "                   cup         41          2       0.22          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3       0.64          1      0.995       0.82\r\n",
      "              sandwich         41          4          1      0.708      0.856      0.657\r\n",
      "              broccoli         41         12      0.259       0.25      0.201      0.135\r\n",
      "                carrot         41         13      0.426       0.12      0.173      0.106\r\n",
      "                 pizza         41         13          1      0.243      0.684      0.383\r\n",
      "                 chair         41         12       0.69      0.667      0.665      0.528\r\n",
      "                 couch         41          1      0.622          1      0.995      0.995\r\n",
      "          dining table         41          7      0.507      0.714      0.565      0.356\r\n",
      "                    tv         41          1      0.323          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.393      0.143     0.0989     0.0455\r\n",
      "                  book         41         38      0.596      0.421      0.474       0.27\r\n",
      "                 clock         41          3      0.566      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.783          1      0.945      0.786\r\n",
      "            toothbrush         41          2       0.44       0.44      0.306      0.266\r\n",
      "Speed: 1.4ms preprocess, 379.3ms inference, 0.0ms loss, 1.5ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train47\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --weight_decay 0.9"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T11:12:31.976338Z",
     "start_time": "2024-05-22T10:42:28.074790Z"
    }
   },
   "id": "7e922cfbf190a7b5",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train48, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=3.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train48\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=c2cac7fca51348d68870b6d1fae1bcb5\r\n",
      "2024-05-22 14:12:42,129 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/c2cac7fca51348d68870b6d1fae1bcb5/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train48', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train48/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train48\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.081      1.117      2.664         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.639      0.581       0.66      0.521\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G       1.06      1.035      2.623         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.525      0.635      0.652      0.517\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.071      1.072      2.614        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.704      0.527      0.644      0.508\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.048     0.9498       2.67         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.707      0.517       0.64      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.9933     0.9686      2.532         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.72      0.504      0.636      0.499\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G      0.985     0.9172      2.543         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.727      0.487      0.626      0.488\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G     0.9697     0.8895      2.486        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.667      0.534       0.63      0.492\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9514     0.8812      2.457        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.735      0.505       0.62      0.485\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G     0.9989     0.8768      2.563        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.761      0.491      0.613      0.483\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G      0.965      0.837      2.462        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.772      0.489      0.613      0.482\r\n",
      "\r\n",
      "10 epochs completed in 0.412 hours.\r\n",
      "Optimizer stripped from runs/detect/train48/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train48/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train48/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.637      0.583       0.66      0.521\r\n",
      "                person         41         99        0.7      0.747      0.846      0.642\r\n",
      "               bicycle         41          2      0.405        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.717      0.588      0.632      0.378\r\n",
      "            motorcycle         41          1      0.786          1      0.995      0.895\r\n",
      "                   bus         41          2      0.606          1      0.995      0.945\r\n",
      "                 train         41          2      0.399        0.5      0.745      0.497\r\n",
      "                 truck         41         10       0.64       0.36      0.531      0.359\r\n",
      "         traffic light         41          8      0.441       0.11      0.259     0.0597\r\n",
      "             stop sign         41          1      0.622          1      0.995      0.895\r\n",
      "                 bench         41          7      0.617      0.429      0.532      0.294\r\n",
      "                  bird         41         20      0.771       0.25      0.341      0.253\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.795       0.84      0.586\r\n",
      "                   cow         41          9      0.728      0.556      0.813      0.631\r\n",
      "                 zebra         41          5       0.78        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.691      0.444      0.701      0.565\r\n",
      "               handbag         41          1      0.714          1      0.995      0.895\r\n",
      "                  kite         41          1      0.627          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.439          1      0.995      0.597\r\n",
      "        baseball glove         41          1       0.64          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.692      0.767      0.913      0.633\r\n",
      "             surfboard         41          2      0.375      0.624      0.745      0.597\r\n",
      "         tennis racket         41          5      0.795      0.781       0.88      0.682\r\n",
      "                   cup         41          2      0.219          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.781          1      0.995      0.776\r\n",
      "              sandwich         41          4          1      0.711      0.856      0.682\r\n",
      "              broccoli         41         12      0.257       0.25      0.201      0.135\r\n",
      "                carrot         41         13      0.432      0.123      0.174      0.106\r\n",
      "                 pizza         41         13          1      0.252      0.684      0.383\r\n",
      "                 chair         41         12      0.687      0.667      0.665      0.528\r\n",
      "                 couch         41          1       0.62          1      0.995      0.995\r\n",
      "          dining table         41          7      0.499      0.714      0.565      0.361\r\n",
      "                    tv         41          1      0.319          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.391      0.143     0.0989     0.0455\r\n",
      "                  book         41         38      0.601      0.447      0.476      0.272\r\n",
      "                 clock         41          3      0.556      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4       0.78          1      0.945      0.786\r\n",
      "            toothbrush         41          2      0.443      0.443      0.306      0.266\r\n",
      "Speed: 1.3ms preprocess, 345.7ms inference, 0.0ms loss, 1.2ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train48\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --dfl 3.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T11:39:05.144463Z",
     "start_time": "2024-05-22T11:12:31.908458Z"
    }
   },
   "id": "e5a862102f522fa5",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train49, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=9.0, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train49\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=d85cf9bafed14adcb7b3753f00b41509\r\n",
      "2024-05-22 14:39:15,799 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/d85cf9bafed14adcb7b3753f00b41509/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train49', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train49/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train49\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.081      1.117      6.851         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.645      0.573      0.662      0.521\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G       1.06      1.037      6.746         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.696      0.529      0.649      0.514\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G       1.07      1.081      6.716        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.707      0.518      0.645      0.507\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.045     0.9592      6.842         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.719        0.5      0.646       0.51\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.9909     0.9929      6.499         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.714      0.507      0.642      0.507\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G      0.979     0.9343      6.496         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.716      0.487      0.635      0.497\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G     0.9625     0.9104      6.366        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.664      0.522      0.632      0.493\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9463      0.899      6.298        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.745      0.507      0.637      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G     0.9917     0.8967      6.568        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.758      0.502      0.634      0.495\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G     0.9577     0.8574      6.305        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.774      0.498      0.629      0.489\r\n",
      "\r\n",
      "10 epochs completed in 0.417 hours.\r\n",
      "Optimizer stripped from runs/detect/train49/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train49/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train49/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.645      0.574      0.661      0.521\r\n",
      "                person         41         99      0.704      0.746      0.848       0.64\r\n",
      "               bicycle         41          2      0.431        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.732      0.588      0.632      0.378\r\n",
      "            motorcycle         41          1      0.813          1      0.995      0.895\r\n",
      "                   bus         41          2      0.615          1      0.995      0.945\r\n",
      "                 train         41          2      0.405        0.5      0.745      0.497\r\n",
      "                 truck         41         10        0.5        0.2       0.53      0.359\r\n",
      "         traffic light         41          8      0.426      0.107      0.259     0.0597\r\n",
      "             stop sign         41          1       0.63          1      0.995      0.895\r\n",
      "                 bench         41          7      0.672      0.429      0.532      0.294\r\n",
      "                  bird         41         20       0.78       0.25      0.342      0.253\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.787       0.84      0.586\r\n",
      "                   cow         41          9      0.739      0.556      0.813      0.631\r\n",
      "                 zebra         41          5      0.785        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.839      0.444      0.704      0.566\r\n",
      "               handbag         41          1      0.747          1      0.995      0.895\r\n",
      "                  kite         41          1      0.641          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.447          1      0.995      0.597\r\n",
      "        baseball glove         41          1       0.65          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.684      0.738      0.913      0.633\r\n",
      "             surfboard         41          2      0.363       0.59      0.745      0.597\r\n",
      "         tennis racket         41          5      0.791      0.765       0.88      0.674\r\n",
      "                   cup         41          2      0.224          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.789          1      0.995      0.776\r\n",
      "              sandwich         41          4          1      0.706      0.856      0.682\r\n",
      "              broccoli         41         12      0.265       0.25      0.201      0.135\r\n",
      "                carrot         41         13      0.414      0.114      0.174      0.106\r\n",
      "                 pizza         41         13          1      0.226      0.686      0.384\r\n",
      "                 chair         41         12      0.701      0.667      0.666      0.528\r\n",
      "                 couch         41          1      0.629          1      0.995      0.995\r\n",
      "          dining table         41          7      0.536      0.714      0.565      0.361\r\n",
      "                    tv         41          1      0.327          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.397      0.143      0.099     0.0455\r\n",
      "                  book         41         38      0.616       0.38      0.476      0.273\r\n",
      "                 clock         41          3      0.584      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.797          1      0.995      0.801\r\n",
      "            toothbrush         41          2      0.424      0.424      0.306      0.266\r\n",
      "Speed: 1.3ms preprocess, 350.0ms inference, 0.0ms loss, 1.6ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train49\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --dfl 9"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T12:05:12.742940Z",
     "start_time": "2024-05-22T11:39:05.140560Z"
    }
   },
   "id": "7589ba123ee3dd42",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train50, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=0.5, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train50\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=60aa0e7ad49c445089918f34788841de\r\n",
      "2024-05-22 15:05:22,333 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/60aa0e7ad49c445089918f34788841de/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train50', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train50/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train50\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.081      1.117      1.142         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.636      0.579       0.66      0.521\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G      1.059      1.031      1.124         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.534      0.615      0.648      0.515\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.073      1.068      1.122        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.699      0.534      0.642      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.047      0.942      1.145         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.707      0.517      0.645      0.503\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.9933     0.9576      1.084         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.734      0.508      0.643      0.505\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G     0.9892     0.9058      1.094         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.744      0.493      0.636      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G     0.9773     0.8787       1.07        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.701      0.528      0.637      0.498\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9586     0.8698      1.058        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.751      0.509      0.625      0.487\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G      1.007     0.8701      1.105        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.733      0.511       0.62      0.485\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G     0.9666      0.823      1.059        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.767      0.492      0.616      0.481\r\n",
      "\r\n",
      "10 epochs completed in 0.441 hours.\r\n",
      "Optimizer stripped from runs/detect/train50/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train50/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train50/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.637       0.58       0.66      0.521\r\n",
      "                person         41         99      0.702      0.747      0.846      0.641\r\n",
      "               bicycle         41          2      0.414        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.722      0.588      0.632      0.378\r\n",
      "            motorcycle         41          1      0.789          1      0.995      0.895\r\n",
      "                   bus         41          2      0.609          1      0.995      0.945\r\n",
      "                 train         41          2      0.402        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.623      0.334      0.531      0.359\r\n",
      "         traffic light         41          8      0.435      0.109      0.259     0.0597\r\n",
      "             stop sign         41          1      0.625          1      0.995      0.895\r\n",
      "                 bench         41          7      0.638      0.429      0.531      0.294\r\n",
      "                  bird         41         20      0.775       0.25      0.341      0.253\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.793       0.84      0.586\r\n",
      "                   cow         41          9      0.732      0.556      0.815      0.632\r\n",
      "                 zebra         41          5      0.781        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.718      0.444      0.701      0.564\r\n",
      "               handbag         41          1       0.72          1      0.995      0.895\r\n",
      "                  kite         41          1      0.635          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.643          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.684      0.735      0.913      0.633\r\n",
      "             surfboard         41          2       0.37      0.609      0.745      0.597\r\n",
      "         tennis racket         41          5      0.794      0.778       0.88      0.682\r\n",
      "                   cup         41          2       0.22          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.641          1      0.995       0.82\r\n",
      "              sandwich         41          4          1      0.708      0.856      0.657\r\n",
      "              broccoli         41         12       0.26       0.25      0.201      0.135\r\n",
      "                carrot         41         13      0.425      0.119      0.174      0.106\r\n",
      "                 pizza         41         13          1      0.242      0.684      0.383\r\n",
      "                 chair         41         12      0.691      0.667      0.665      0.528\r\n",
      "                 couch         41          1      0.622          1      0.995      0.995\r\n",
      "          dining table         41          7      0.507      0.714      0.565      0.356\r\n",
      "                    tv         41          1      0.323          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.393      0.143     0.0989     0.0455\r\n",
      "                  book         41         38      0.622      0.433      0.475      0.271\r\n",
      "                 clock         41          3      0.568      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.784          1      0.945      0.786\r\n",
      "            toothbrush         41          2      0.439      0.439      0.306      0.266\r\n",
      "Speed: 1.2ms preprocess, 347.6ms inference, 0.0ms loss, 1.3ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train50\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --kobj 0.5"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T12:32:49.018838Z",
     "start_time": "2024-05-22T12:05:12.690134Z"
    }
   },
   "id": "2087bddf271e22a4",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train54, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=6.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train54\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=ca50523d0fdb4969a68a60242d3148d8\r\n",
      "2024-05-22 16:35:39,229 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/ca50523d0fdb4969a68a60242d3148d8/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train54', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train54/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train54\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.081      1.117      1.142         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.636      0.579       0.66      0.521\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G      1.059      1.031      1.124         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.534      0.615      0.648      0.515\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.073      1.068      1.122        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.699      0.534      0.642      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.047      0.942      1.145         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.707      0.517      0.645      0.503\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.9933     0.9576      1.084         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.734      0.508      0.643      0.505\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G     0.9892     0.9058      1.094         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.744      0.493      0.636      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G     0.9773     0.8787       1.07        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.701      0.528      0.637      0.498\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9586     0.8698      1.058        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.751      0.509      0.625      0.487\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G      1.007     0.8701      1.105        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.733      0.511       0.62      0.485\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G     0.9666      0.823      1.059        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.767      0.492      0.616      0.481\r\n",
      "\r\n",
      "10 epochs completed in 0.402 hours.\r\n",
      "Optimizer stripped from runs/detect/train54/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train54/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train54/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.637       0.58       0.66      0.521\r\n",
      "                person         41         99      0.702      0.747      0.846      0.641\r\n",
      "               bicycle         41          2      0.414        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.722      0.588      0.632      0.378\r\n",
      "            motorcycle         41          1      0.789          1      0.995      0.895\r\n",
      "                   bus         41          2      0.609          1      0.995      0.945\r\n",
      "                 train         41          2      0.402        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.623      0.334      0.531      0.359\r\n",
      "         traffic light         41          8      0.435      0.109      0.259     0.0597\r\n",
      "             stop sign         41          1      0.625          1      0.995      0.895\r\n",
      "                 bench         41          7      0.638      0.429      0.531      0.294\r\n",
      "                  bird         41         20      0.775       0.25      0.341      0.253\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.793       0.84      0.586\r\n",
      "                   cow         41          9      0.732      0.556      0.815      0.632\r\n",
      "                 zebra         41          5      0.781        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.718      0.444      0.701      0.564\r\n",
      "               handbag         41          1       0.72          1      0.995      0.895\r\n",
      "                  kite         41          1      0.635          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.643          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.684      0.735      0.913      0.633\r\n",
      "             surfboard         41          2       0.37      0.609      0.745      0.597\r\n",
      "         tennis racket         41          5      0.794      0.778       0.88      0.682\r\n",
      "                   cup         41          2       0.22          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.641          1      0.995       0.82\r\n",
      "              sandwich         41          4          1      0.708      0.856      0.657\r\n",
      "              broccoli         41         12       0.26       0.25      0.201      0.135\r\n",
      "                carrot         41         13      0.425      0.119      0.174      0.106\r\n",
      "                 pizza         41         13          1      0.242      0.684      0.383\r\n",
      "                 chair         41         12      0.691      0.667      0.665      0.528\r\n",
      "                 couch         41          1      0.622          1      0.995      0.995\r\n",
      "          dining table         41          7      0.507      0.714      0.565      0.356\r\n",
      "                    tv         41          1      0.323          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.393      0.143     0.0989     0.0455\r\n",
      "                  book         41         38      0.622      0.433      0.475      0.271\r\n",
      "                 clock         41          3      0.568      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.784          1      0.945      0.786\r\n",
      "            toothbrush         41          2      0.439      0.439      0.306      0.266\r\n",
      "Speed: 1.2ms preprocess, 346.6ms inference, 0.0ms loss, 1.4ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train54\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --kobj 6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T14:00:32.435157Z",
     "start_time": "2024-05-22T13:35:29.076853Z"
    }
   },
   "id": "86986fbf0ec4078d",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train55, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=1.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train55\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=7475f9af746a4bcaa38305b719580aa7\r\n",
      "2024-05-22 17:27:03,272 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/7475f9af746a4bcaa38305b719580aa7/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train55', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train55/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train55\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.081      1.117      1.142         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.636      0.579       0.66      0.521\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G      1.059      1.031      1.124         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.534      0.615      0.648      0.515\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.073      1.068      1.122        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.699      0.534      0.642      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.047      0.942      1.145         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.707      0.517      0.645      0.503\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.9933     0.9576      1.084         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.734      0.508      0.643      0.505\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G     0.9892     0.9058      1.094         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.744      0.493      0.636      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G     0.9773     0.8787       1.07        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.701      0.528      0.637      0.498\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9586     0.8698      1.058        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.751      0.509      0.625      0.487\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G      1.007     0.8701      1.105        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.733      0.511       0.62      0.485\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G     0.9666      0.823      1.059        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.767      0.492      0.616      0.481\r\n",
      "\r\n",
      "10 epochs completed in 0.401 hours.\r\n",
      "Optimizer stripped from runs/detect/train55/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train55/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train55/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.637       0.58       0.66      0.521\r\n",
      "                person         41         99      0.702      0.747      0.846      0.641\r\n",
      "               bicycle         41          2      0.414        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.722      0.588      0.632      0.378\r\n",
      "            motorcycle         41          1      0.789          1      0.995      0.895\r\n",
      "                   bus         41          2      0.609          1      0.995      0.945\r\n",
      "                 train         41          2      0.402        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.623      0.334      0.531      0.359\r\n",
      "         traffic light         41          8      0.435      0.109      0.259     0.0597\r\n",
      "             stop sign         41          1      0.625          1      0.995      0.895\r\n",
      "                 bench         41          7      0.638      0.429      0.531      0.294\r\n",
      "                  bird         41         20      0.775       0.25      0.341      0.253\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.793       0.84      0.586\r\n",
      "                   cow         41          9      0.732      0.556      0.815      0.632\r\n",
      "                 zebra         41          5      0.781        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.718      0.444      0.701      0.564\r\n",
      "               handbag         41          1       0.72          1      0.995      0.895\r\n",
      "                  kite         41          1      0.635          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.643          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.684      0.735      0.913      0.633\r\n",
      "             surfboard         41          2       0.37      0.609      0.745      0.597\r\n",
      "         tennis racket         41          5      0.794      0.778       0.88      0.682\r\n",
      "                   cup         41          2       0.22          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.641          1      0.995       0.82\r\n",
      "              sandwich         41          4          1      0.708      0.856      0.657\r\n",
      "              broccoli         41         12       0.26       0.25      0.201      0.135\r\n",
      "                carrot         41         13      0.425      0.119      0.174      0.106\r\n",
      "                 pizza         41         13          1      0.242      0.684      0.383\r\n",
      "                 chair         41         12      0.691      0.667      0.665      0.528\r\n",
      "                 couch         41          1      0.622          1      0.995      0.995\r\n",
      "          dining table         41          7      0.507      0.714      0.565      0.356\r\n",
      "                    tv         41          1      0.323          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.393      0.143     0.0989     0.0455\r\n",
      "                  book         41         38      0.622      0.433      0.475      0.271\r\n",
      "                 clock         41          3      0.568      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.784          1      0.945      0.786\r\n",
      "            toothbrush         41          2      0.439      0.439      0.306      0.266\r\n",
      "Speed: 1.3ms preprocess, 358.1ms inference, 0.0ms loss, 1.4ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train55\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --pose 1.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T14:52:08.844910Z",
     "start_time": "2024-05-22T14:26:52.793639Z"
    }
   },
   "id": "2b3161c3d3c2d8df",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train56, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=10.0, dfl=1.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train56\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=0a44e8bac5824d15967d0c7c5ae45e8e\r\n",
      "2024-05-22 17:52:19,670 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/0a44e8bac5824d15967d0c7c5ae45e8e/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train56', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train56/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train56\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.082      22.34      1.142         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.643      0.573      0.661      0.523\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G      1.064      20.51      1.129         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.568      0.595      0.648      0.514\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.085      21.18       1.13        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.711       0.51      0.637      0.507\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.066       18.7      1.157         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.689      0.525      0.638      0.505\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G      1.015      18.76      1.098         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.704      0.518      0.634      0.501\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G      1.012      17.77      1.109         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.709      0.506      0.631       0.49\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G      1.013      17.13      1.093        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.683      0.524      0.628      0.484\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.9966      17.16      1.081        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.728       0.51      0.615      0.477\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G       1.05      17.16      1.127        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.707      0.512      0.611      0.477\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G      1.013      16.25      1.085        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.702      0.519      0.612      0.478\r\n",
      "\r\n",
      "10 epochs completed in 0.400 hours.\r\n",
      "Optimizer stripped from runs/detect/train56/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train56/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train56/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.641      0.574      0.661      0.522\r\n",
      "                person         41         99      0.703      0.741      0.844      0.641\r\n",
      "               bicycle         41          2      0.433        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.742      0.592      0.648      0.382\r\n",
      "            motorcycle         41          1      0.798          1      0.995      0.895\r\n",
      "                   bus         41          2      0.617          1      0.995      0.945\r\n",
      "                 train         41          2      0.409        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.584      0.284      0.535      0.363\r\n",
      "         traffic light         41          8      0.419      0.105      0.258     0.0595\r\n",
      "             stop sign         41          1       0.63          1      0.995      0.895\r\n",
      "                 bench         41          7      0.694      0.429      0.534      0.295\r\n",
      "                  bird         41         20      0.781       0.25       0.34      0.252\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1       0.79       0.84      0.586\r\n",
      "                   cow         41          9      0.744      0.556      0.807      0.632\r\n",
      "                 zebra         41          5      0.782        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.199      0.139\r\n",
      "              umbrella         41          9      0.797      0.444      0.701      0.565\r\n",
      "               handbag         41          1      0.723          1      0.995      0.895\r\n",
      "                  kite         41          1      0.641          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.422          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.649          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.682      0.667      0.913      0.633\r\n",
      "             surfboard         41          2      0.359      0.578      0.745      0.597\r\n",
      "         tennis racket         41          5      0.792       0.77      0.866      0.675\r\n",
      "                   cup         41          2      0.223          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.648          1      0.995       0.82\r\n",
      "              sandwich         41          4          1      0.701      0.856      0.684\r\n",
      "              broccoli         41         12      0.264       0.25      0.203      0.136\r\n",
      "                carrot         41         13      0.408      0.111      0.173      0.107\r\n",
      "                 pizza         41         13          1      0.231      0.687      0.384\r\n",
      "                 chair         41         12      0.694      0.667      0.665      0.527\r\n",
      "                 couch         41          1       0.63          1      0.995      0.995\r\n",
      "          dining table         41          7      0.526      0.714      0.565      0.379\r\n",
      "                    tv         41          1      0.331          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.398      0.143        0.1     0.0481\r\n",
      "                  book         41         38      0.614      0.378      0.474       0.27\r\n",
      "                 clock         41          3      0.589      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.783          1      0.945      0.756\r\n",
      "            toothbrush         41          2      0.429      0.429      0.306      0.266\r\n",
      "Speed: 1.3ms preprocess, 338.8ms inference, 0.0ms loss, 1.4ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train56\u001B[0m\r\n",
      "Skipping upload, could not find object file '/var/folders/jr/7cpxm2sj4y74r__lw8nqpvfw0000gn/T/tmpw9e15sh9.png'\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --cls 10.0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:17:48.399301Z",
     "start_time": "2024-05-22T14:52:08.815490Z"
    }
   },
   "id": "b26fafe37659f66f",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train57, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.5, cls=0.5, dfl=1.5, pose=12.0, kobj=2.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train57\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=1c2aa23b96e7422ea5cf83667c4492f9\r\n",
      "2024-05-22 18:17:58,412 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/1c2aa23b96e7422ea5cf83667c4492f9/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train57', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train57/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train57\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G    0.07209      1.117      1.142         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.64      0.575       0.66      0.522\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G    0.07071      1.027      1.125         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.552      0.609       0.65      0.516\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G    0.07158      1.058      1.122        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.68      0.539      0.645      0.508\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G    0.06989     0.9332      1.146         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.698      0.515      0.644      0.504\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G     0.0668     0.9416      1.088         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.711        0.5       0.63      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G     0.0666      0.891      1.095         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.661      0.526      0.638      0.494\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G    0.06626     0.8634      1.076        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.712      0.528      0.635      0.487\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G     0.0651     0.8543      1.067        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.75      0.497      0.618      0.473\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G    0.06858     0.8565      1.111        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.768      0.497      0.618      0.476\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G    0.06584     0.8154      1.064        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.755        0.5      0.617      0.474\r\n",
      "\r\n",
      "10 epochs completed in 0.446 hours.\r\n",
      "Optimizer stripped from runs/detect/train57/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train57/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train57/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.64      0.575       0.66      0.522\r\n",
      "                person         41         99      0.704      0.745      0.845       0.64\r\n",
      "               bicycle         41          2      0.428        0.5        0.5       0.45\r\n",
      "                   car         41         34      0.744      0.597      0.648      0.382\r\n",
      "            motorcycle         41          1      0.799          1      0.995      0.895\r\n",
      "                   bus         41          2      0.615          1      0.995      0.945\r\n",
      "                 train         41          2      0.406        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.603      0.304      0.532       0.36\r\n",
      "         traffic light         41          8      0.424      0.106      0.259     0.0587\r\n",
      "             stop sign         41          1      0.629          1      0.995      0.895\r\n",
      "                 bench         41          7      0.676      0.429      0.534      0.296\r\n",
      "                  bird         41         20      0.779       0.25      0.341      0.252\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1       0.79       0.84      0.586\r\n",
      "                   cow         41          9      0.739      0.556      0.811      0.633\r\n",
      "                 zebra         41          5      0.783        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.756      0.444      0.704      0.566\r\n",
      "               handbag         41          1      0.726          1      0.995      0.895\r\n",
      "                  kite         41          1      0.638          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.421          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.647          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.669      0.667      0.913      0.633\r\n",
      "             surfboard         41          2      0.363      0.589      0.745      0.597\r\n",
      "         tennis racket         41          5      0.792      0.769       0.88      0.682\r\n",
      "                   cup         41          2      0.222          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.645          1      0.995       0.82\r\n",
      "              sandwich         41          4          1      0.703      0.856       0.66\r\n",
      "              broccoli         41         12      0.262       0.25      0.202      0.136\r\n",
      "                carrot         41         13      0.414      0.114      0.173      0.107\r\n",
      "                 pizza         41         13          1       0.23      0.686      0.384\r\n",
      "                 chair         41         12      0.694      0.667      0.665      0.527\r\n",
      "                 couch         41          1      0.628          1      0.995      0.995\r\n",
      "          dining table         41          7      0.522      0.714      0.565      0.354\r\n",
      "                    tv         41          1       0.33          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.397      0.143     0.0995     0.0458\r\n",
      "                  book         41         38      0.619      0.384      0.472      0.269\r\n",
      "                 clock         41          3      0.582      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.784          1      0.945      0.756\r\n",
      "            toothbrush         41          2      0.431      0.431      0.306      0.266\r\n",
      "Speed: 1.2ms preprocess, 358.4ms inference, 0.0ms loss, 1.2ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train57\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --box 0.5\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T15:46:21.811654Z",
     "start_time": "2024-05-22T15:17:48.410387Z"
    }
   },
   "id": "15ed73f528546aa3",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train58, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=12.0, cls=0.0, dfl=0.0, pose=0.0, kobj=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train58\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=733b3483a00a42ad83590aad40b95f6a\r\n",
      "2024-05-22 18:51:42,960 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/733b3483a00a42ad83590aad40b95f6a/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train58', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train58/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train58\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G      1.729          0          0         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.619      0.594      0.662      0.523\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G      1.702          0          0         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.593      0.614      0.646      0.512\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G      1.732          0          0        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.56      0.593      0.642       0.51\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G      1.685          0          0         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.603      0.576      0.642      0.509\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G      1.606          0          0         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.618      0.551       0.64      0.508\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G      1.589          0          0         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.625      0.556      0.639      0.503\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G      1.568          0          0        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.621      0.564      0.641      0.502\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G      1.543          0          0        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.61      0.559      0.635      0.494\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G      1.612          0          0        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.674      0.522      0.637      0.496\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G      1.559          0          0        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.693      0.517      0.632      0.495\r\n",
      "\r\n",
      "10 epochs completed in 0.410 hours.\r\n",
      "Optimizer stripped from runs/detect/train58/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train58/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train58/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.617      0.595      0.661      0.523\r\n",
      "                person         41         99      0.697      0.766      0.846      0.637\r\n",
      "               bicycle         41          2      0.391        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.709      0.647       0.63      0.377\r\n",
      "            motorcycle         41          1      0.763          1      0.995      0.895\r\n",
      "                   bus         41          2      0.599          1      0.995      0.945\r\n",
      "                 train         41          2      0.394        0.5      0.745      0.522\r\n",
      "                 truck         41         10      0.697      0.463      0.531      0.358\r\n",
      "         traffic light         41          8      0.453      0.113      0.259     0.0598\r\n",
      "             stop sign         41          1      0.621          1      0.995      0.895\r\n",
      "                 bench         41          7      0.567      0.429      0.526      0.291\r\n",
      "                  bird         41         20      0.767       0.25       0.34      0.251\r\n",
      "                   cat         41          1          0          0      0.249      0.249\r\n",
      "                 horse         41          6          1      0.801       0.84      0.586\r\n",
      "                   cow         41          9      0.721      0.556      0.815      0.632\r\n",
      "                 zebra         41          5          1      0.778      0.809      0.712\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.759      0.444      0.703      0.566\r\n",
      "               handbag         41          1      0.719          1      0.995      0.895\r\n",
      "                  kite         41          1      0.624          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.434          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.638          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.705      0.819      0.913      0.633\r\n",
      "             surfboard         41          2      0.388      0.664      0.745      0.597\r\n",
      "         tennis racket         41          5      0.771        0.8      0.866      0.675\r\n",
      "                   cup         41          2       0.22          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.786          1      0.995      0.776\r\n",
      "              sandwich         41          4          1      0.716      0.845      0.677\r\n",
      "              broccoli         41         12      0.256       0.25      0.199      0.134\r\n",
      "                carrot         41         13      0.424      0.119      0.172      0.105\r\n",
      "                 pizza         41         13          1      0.285      0.681      0.384\r\n",
      "                 chair         41         12      0.683      0.667      0.665      0.527\r\n",
      "                 couch         41          1      0.616          1      0.995      0.995\r\n",
      "          dining table         41          7      0.494      0.714      0.568      0.362\r\n",
      "                    tv         41          1      0.293          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.389      0.143     0.0983     0.0449\r\n",
      "                  book         41         38      0.581      0.447      0.476      0.273\r\n",
      "                 clock         41          3      0.531      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.781          1      0.945      0.786\r\n",
      "            toothbrush         41          2      0.458      0.458       0.31      0.269\r\n",
      "Speed: 2.7ms preprocess, 1512.2ms inference, 0.0ms loss, 1.5ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train58\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --box 12 --cls 0 --pose 0 --kobj 0 --dfl 0"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:17:59.352955Z",
     "start_time": "2024-05-22T15:51:32.508005Z"
    }
   },
   "id": "36c3ddc5dd4414ea",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train59, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.0, cls=12.0, dfl=0.0, pose=0.0, kobj=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train59\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=b21b74b021234e6bbfbe086d1bbdbe63\r\n",
      "2024-05-22 19:18:09,721 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/b21b74b021234e6bbfbe086d1bbdbe63/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train59', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train59/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train59\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G          0      26.81          0         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.643      0.573      0.661      0.524\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G          0      24.59          0         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.568      0.589      0.648      0.513\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G          0      25.39          0        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.695      0.526      0.647      0.514\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G          0      22.55          0         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.732      0.496      0.639      0.506\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G          0      22.52          0         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.725      0.511      0.634      0.502\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G          0      21.23          0         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.635      0.558      0.637      0.501\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G          0      20.53          0        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.679      0.525      0.629       0.49\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G          0       20.6          0        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.749        0.5      0.617      0.482\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G          0       20.7          0        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.736      0.503      0.615      0.478\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G          0      19.58          0        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.714       0.51      0.611      0.479\r\n",
      "\r\n",
      "10 epochs completed in 0.425 hours.\r\n",
      "Optimizer stripped from runs/detect/train59/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train59/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train59/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.643      0.573      0.661      0.524\r\n",
      "                person         41         99      0.702      0.739      0.844      0.641\r\n",
      "               bicycle         41          2      0.437        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.741       0.59      0.648      0.382\r\n",
      "            motorcycle         41          1      0.799          1      0.995      0.895\r\n",
      "                   bus         41          2      0.618          1      0.995      0.945\r\n",
      "                 train         41          2       0.41        0.5      0.745      0.547\r\n",
      "                 truck         41         10      0.558      0.258      0.535      0.363\r\n",
      "         traffic light         41          8      0.417      0.104      0.258     0.0586\r\n",
      "             stop sign         41          1      0.631          1      0.995      0.895\r\n",
      "                 bench         41          7      0.704      0.429      0.536      0.297\r\n",
      "                  bird         41         20      0.782       0.25       0.34      0.252\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.789       0.84      0.586\r\n",
      "                   cow         41          9      0.746      0.556      0.807      0.632\r\n",
      "                 zebra         41          5      0.782        0.6      0.769      0.692\r\n",
      "              backpack         41          1          1          0      0.199      0.139\r\n",
      "              umbrella         41          9      0.859      0.444      0.701      0.564\r\n",
      "               handbag         41          1      0.725          1      0.995      0.895\r\n",
      "                  kite         41          1      0.642          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.424          1      0.995      0.597\r\n",
      "        baseball glove         41          1       0.65          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.685      0.667      0.913       0.65\r\n",
      "             surfboard         41          2      0.358      0.575      0.745      0.597\r\n",
      "         tennis racket         41          5      0.793       0.77      0.866      0.676\r\n",
      "                   cup         41          2      0.224          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3       0.65          1      0.995       0.82\r\n",
      "              sandwich         41          4          1        0.7      0.856      0.684\r\n",
      "              broccoli         41         12      0.265       0.25      0.203      0.136\r\n",
      "                carrot         41         13      0.405       0.11      0.173      0.107\r\n",
      "                 pizza         41         13          1       0.23       0.69      0.386\r\n",
      "                 chair         41         12      0.695      0.667      0.665      0.527\r\n",
      "                 couch         41          1      0.631          1      0.995      0.995\r\n",
      "          dining table         41          7      0.531      0.714      0.565       0.38\r\n",
      "                    tv         41          1      0.331          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.399      0.143        0.1     0.0482\r\n",
      "                  book         41         38      0.612      0.374      0.474      0.271\r\n",
      "                 clock         41          3      0.592      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.782          1      0.945      0.756\r\n",
      "            toothbrush         41          2      0.427      0.427      0.306      0.266\r\n",
      "Speed: 1.3ms preprocess, 355.2ms inference, 0.0ms loss, 1.3ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train59\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --cls 12 --box 0 --pose 0 --kobj 0 --dfl 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T16:44:24.529416Z",
     "start_time": "2024-05-22T16:17:59.358207Z"
    }
   },
   "id": "4d56f968faadbe34",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train60, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.0, cls=0.0, dfl=0.0, pose=12.0, kobj=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train60\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=b59bea606631452a9f1ace430354e5b4\r\n",
      "2024-05-22 19:44:34,400 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/b59bea606631452a9f1ace430354e5b4/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train60', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train60/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train60\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G          0          0          0         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.642      0.584       0.66       0.52\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G          0          0          0         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.66      0.581      0.651      0.514\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G          0          0          0        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.653       0.58      0.647      0.511\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G          0          0          0         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.64      0.587      0.639        0.5\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G          0          0          0         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.623      0.604      0.637      0.501\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G          0          0          0         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.548      0.622      0.637      0.499\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G          0          0          0        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.557      0.649      0.636      0.497\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G          0          0          0        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.558      0.645      0.637      0.493\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G          0          0          0        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.59       0.64      0.638      0.493\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G          0          0          0        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.587      0.628      0.633      0.489\r\n",
      "\r\n",
      "10 epochs completed in 0.407 hours.\r\n",
      "Optimizer stripped from runs/detect/train60/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train60/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train60/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.642      0.584       0.66       0.52\r\n",
      "                person         41         99      0.701      0.747      0.848      0.641\r\n",
      "               bicycle         41          2      0.414        0.5      0.499        0.4\r\n",
      "                   car         41         34       0.72      0.607      0.629      0.376\r\n",
      "            motorcycle         41          1      0.769          1      0.995      0.895\r\n",
      "                   bus         41          2      0.607          1      0.995      0.896\r\n",
      "                 train         41          2      0.404        0.5      0.745      0.547\r\n",
      "                 truck         41         10      0.629      0.344      0.529      0.348\r\n",
      "         traffic light         41          8      0.435      0.109      0.259     0.0607\r\n",
      "             stop sign         41          1       0.63          1      0.995      0.895\r\n",
      "                 bench         41          7      0.638      0.429      0.528       0.29\r\n",
      "                  bird         41         20      0.775       0.25      0.346      0.252\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.798       0.84      0.586\r\n",
      "                   cow         41          9      0.738      0.556      0.808      0.633\r\n",
      "                 zebra         41          5       0.78        0.6      0.768      0.675\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.856      0.444      0.702      0.566\r\n",
      "               handbag         41          1      0.724          1      0.995      0.895\r\n",
      "                  kite         41          1      0.619          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.647          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.709      0.835      0.913       0.65\r\n",
      "             surfboard         41          2      0.381      0.644      0.745      0.597\r\n",
      "         tennis racket         41          5      0.754        0.8       0.88      0.666\r\n",
      "                   cup         41          2      0.223          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.798          1      0.995      0.776\r\n",
      "              sandwich         41          4          1      0.706      0.856      0.709\r\n",
      "              broccoli         41         12      0.263       0.25      0.205      0.138\r\n",
      "                carrot         41         13      0.396      0.106      0.172      0.106\r\n",
      "                 pizza         41         13          1      0.285      0.687       0.38\r\n",
      "                 chair         41         12      0.687      0.667      0.665      0.527\r\n",
      "                 couch         41          1      0.628          1      0.995      0.995\r\n",
      "          dining table         41          7      0.496      0.714      0.561      0.376\r\n",
      "                    tv         41          1      0.303          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.394      0.143     0.0986     0.0505\r\n",
      "                  book         41         38      0.646      0.385      0.474      0.278\r\n",
      "                 clock         41          3      0.546      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.783          1      0.945      0.756\r\n",
      "            toothbrush         41          2      0.443      0.443        0.3      0.262\r\n",
      "Speed: 1.2ms preprocess, 337.9ms inference, 0.0ms loss, 1.4ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train60\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --pose 12 --box 0 --cls 0 --kobj 0 --dfl 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T17:09:45.784312Z",
     "start_time": "2024-05-22T16:44:24.539635Z"
    }
   },
   "id": "b8a1f600039d60be",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train61, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.0, cls=0.0, dfl=0.0, pose=0.0, kobj=12.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train61\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=cdffacc597604bd7a7c430ab403a429f\r\n",
      "2024-05-22 20:09:56,822 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/cdffacc597604bd7a7c430ab403a429f/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train61', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train61/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train61\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G          0          0          0         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.642      0.584       0.66       0.52\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G          0          0          0         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.66      0.581      0.651      0.514\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G          0          0          0        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.653       0.58      0.647      0.511\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G          0          0          0         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.64      0.587      0.639        0.5\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G          0          0          0         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.623      0.604      0.637      0.501\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G          0          0          0         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.548      0.622      0.637      0.499\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G          0          0          0        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.557      0.649      0.636      0.497\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G          0          0          0        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.558      0.645      0.637      0.493\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G          0          0          0        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356       0.59       0.64      0.638      0.493\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G          0          0          0        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.587      0.628      0.633      0.489\r\n",
      "\r\n",
      "10 epochs completed in 0.404 hours.\r\n",
      "Optimizer stripped from runs/detect/train61/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train61/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train61/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.642      0.584       0.66       0.52\r\n",
      "                person         41         99      0.701      0.747      0.848      0.641\r\n",
      "               bicycle         41          2      0.414        0.5      0.499        0.4\r\n",
      "                   car         41         34       0.72      0.607      0.629      0.376\r\n",
      "            motorcycle         41          1      0.769          1      0.995      0.895\r\n",
      "                   bus         41          2      0.607          1      0.995      0.896\r\n",
      "                 train         41          2      0.404        0.5      0.745      0.547\r\n",
      "                 truck         41         10      0.629      0.344      0.529      0.348\r\n",
      "         traffic light         41          8      0.435      0.109      0.259     0.0607\r\n",
      "             stop sign         41          1       0.63          1      0.995      0.895\r\n",
      "                 bench         41          7      0.638      0.429      0.528       0.29\r\n",
      "                  bird         41         20      0.775       0.25      0.346      0.252\r\n",
      "                   cat         41          1          1          0      0.199      0.199\r\n",
      "                 horse         41          6          1      0.798       0.84      0.586\r\n",
      "                   cow         41          9      0.738      0.556      0.808      0.633\r\n",
      "                 zebra         41          5       0.78        0.6      0.768      0.675\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9      0.856      0.444      0.702      0.566\r\n",
      "               handbag         41          1      0.724          1      0.995      0.895\r\n",
      "                  kite         41          1      0.619          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.647          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.709      0.835      0.913       0.65\r\n",
      "             surfboard         41          2      0.381      0.644      0.745      0.597\r\n",
      "         tennis racket         41          5      0.754        0.8       0.88      0.666\r\n",
      "                   cup         41          2      0.223          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.798          1      0.995      0.776\r\n",
      "              sandwich         41          4          1      0.706      0.856      0.709\r\n",
      "              broccoli         41         12      0.263       0.25      0.205      0.138\r\n",
      "                carrot         41         13      0.396      0.106      0.172      0.106\r\n",
      "                 pizza         41         13          1      0.285      0.687       0.38\r\n",
      "                 chair         41         12      0.687      0.667      0.665      0.527\r\n",
      "                 couch         41          1      0.628          1      0.995      0.995\r\n",
      "          dining table         41          7      0.496      0.714      0.561      0.376\r\n",
      "                    tv         41          1      0.303          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.394      0.143     0.0986     0.0505\r\n",
      "                  book         41         38      0.646      0.385      0.474      0.278\r\n",
      "                 clock         41          3      0.546      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4      0.783          1      0.945      0.756\r\n",
      "            toothbrush         41          2      0.443      0.443        0.3      0.262\r\n",
      "Speed: 1.3ms preprocess, 354.1ms inference, 0.0ms loss, 2.8ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train61\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --kobj 12 --box 0 --cls 0 --pose 0 --dfl 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T17:53:52.889086Z",
     "start_time": "2024-05-22T17:09:45.790922Z"
    }
   },
   "id": "bdbc0b7e2cc6c5",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train63, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.0, cls=0.0, dfl=12.0, pose=0.0, kobj=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train63\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=e3bf952fe3ce4c7e933290aaeb6fef57\r\n",
      "2024-05-22 21:12:10,019 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/e3bf952fe3ce4c7e933290aaeb6fef57/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train63', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "Plotting labels to runs/detect/train63/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train63\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G          0          0      9.135         66        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.668      0.577      0.663      0.524\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       2/10         0G          0          0          9         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.537      0.633      0.653      0.517\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       3/10         0G          0          0      8.957        111        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.608      0.574      0.646      0.508\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       4/10         0G          0          0      9.112         98        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.608      0.577      0.646      0.507\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       5/10         0G          0          0      8.666         52        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.628      0.555      0.644      0.505\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       6/10         0G          0          0      8.686         99        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.703      0.501      0.643      0.499\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       7/10         0G          0          0      8.488        188        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.711      0.496      0.641      0.493\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       8/10         0G          0          0      8.442        147        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.728      0.501       0.64      0.492\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       9/10         0G          0          0      8.747        100        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.721      0.502      0.651      0.495\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "      10/10         0G          0          0      8.443        110        640: 1\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.728      0.501      0.637      0.488\r\n",
      "\r\n",
      "10 epochs completed in 0.419 hours.\r\n",
      "Optimizer stripped from runs/detect/train63/weights/last.pt, 18.6MB\r\n",
      "Optimizer stripped from runs/detect/train63/weights/best.pt, 18.6MB\r\n",
      "\r\n",
      "Validating runs/detect/train63/weights/best.pt...\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\r\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\r\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  m\r\n",
      "                   all         41        356      0.668      0.578      0.663      0.522\r\n",
      "                person         41         99      0.703      0.743      0.846       0.64\r\n",
      "               bicycle         41          2      0.443        0.5        0.5        0.4\r\n",
      "                   car         41         34      0.731      0.588       0.63      0.378\r\n",
      "            motorcycle         41          1      0.823          1      0.995      0.895\r\n",
      "                   bus         41          2      0.619          1      0.995      0.945\r\n",
      "                 train         41          2      0.407        0.5      0.745      0.497\r\n",
      "                 truck         41         10      0.748      0.298      0.532      0.359\r\n",
      "         traffic light         41          8      0.422      0.105      0.259     0.0598\r\n",
      "             stop sign         41          1      0.638          1      0.995      0.895\r\n",
      "                 bench         41          7      0.708      0.429       0.53      0.293\r\n",
      "                  bird         41         20      0.788       0.25       0.34      0.252\r\n",
      "                   cat         41          1          1          0      0.249      0.249\r\n",
      "                 horse         41          6          1      0.785       0.84      0.586\r\n",
      "                   cow         41          9      0.744      0.556      0.809      0.632\r\n",
      "                 zebra         41          5          1      0.769      0.808      0.711\r\n",
      "              backpack         41          1          1          0      0.166      0.116\r\n",
      "              umbrella         41          9          1      0.444      0.704      0.566\r\n",
      "               handbag         41          1      0.779          1      0.995      0.895\r\n",
      "                  kite         41          1      0.643          1      0.995      0.796\r\n",
      "          baseball bat         41          1      0.449          1      0.995      0.597\r\n",
      "        baseball glove         41          1      0.657          1      0.995      0.995\r\n",
      "            skateboard         41          3      0.684      0.738      0.913      0.633\r\n",
      "             surfboard         41          2      0.366      0.597      0.745      0.597\r\n",
      "         tennis racket         41          5      0.791      0.765       0.88       0.67\r\n",
      "                   cup         41          2       0.23          1      0.995       0.92\r\n",
      "                  fork         41          1          1          0      0.497      0.448\r\n",
      "                  bowl         41          3      0.802          1      0.995      0.779\r\n",
      "              sandwich         41          4          1      0.703      0.856      0.682\r\n",
      "              broccoli         41         12      0.272       0.25      0.202      0.134\r\n",
      "                carrot         41         13       0.39      0.103       0.17      0.104\r\n",
      "                 pizza         41         13          1      0.222      0.683      0.386\r\n",
      "                 chair         41         12      0.702      0.667      0.668      0.527\r\n",
      "                 couch         41          1      0.638          1      0.995      0.995\r\n",
      "          dining table         41          7      0.552      0.714      0.565      0.361\r\n",
      "                    tv         41          1       0.32          1      0.995      0.995\r\n",
      "                laptop         41          1          0          0      0.332      0.133\r\n",
      "            cell phone         41          7      0.401      0.143     0.0993     0.0455\r\n",
      "                  book         41         38      0.602      0.316      0.472       0.27\r\n",
      "                 clock         41          3      0.589      0.667       0.56      0.438\r\n",
      "              scissors         41          1          1          0          0          0\r\n",
      "            teddy bear         41          4          1      0.987      0.995      0.802\r\n",
      "            toothbrush         41          2      0.416      0.416      0.306      0.266\r\n",
      "Speed: 1.2ms preprocess, 355.6ms inference, 0.0ms loss, 1.4ms postprocess per image\r\n",
      "Results saved to \u001B[1mruns/detect/train63\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --dfl 12 --box 0 --cls 0 --pose 0 --kobj 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T18:38:05.380804Z",
     "start_time": "2024-05-22T18:11:58.537294Z"
    }
   },
   "id": "cfaff150abff0424",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\r\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "New https://pypi.org/project/ultralytics/8.2.19 available üòÉ Update with 'pip install -U ultralytics'\r\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 MPS (Apple M1 Pro)\r\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=mps, workers=8, project=None, name=train64, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.0, cls=0.0, dfl=20.0, pose=0.0, kobj=0.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train64\r\n",
      "\r\n",
      "                   from  n    params  module                                       arguments                     \r\n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \r\n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \r\n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \r\n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \r\n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \r\n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \r\n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \r\n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \r\n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \r\n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \r\n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \r\n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \r\n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \r\n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \r\n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \r\n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \r\n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \r\n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \r\n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \r\n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \r\n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \r\n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\r\n",
      "\r\n",
      "Transferred 427/427 items from pretrained weights\r\n",
      "ClearML Task: created new task id=b57872302b144e388c5fe1bbdfee7d85\r\n",
      "2024-05-23 09:04:48,541 - clearml.Task - INFO - No repository found, storing script code instead\r\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\r\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/b57872302b144e388c5fe1bbdfee7d85/output/log\r\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train64', view at http://localhost:6006/\r\n",
      "Freezing layer 'model.24.dfl.conv.weight'\r\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\r\n",
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralyti\u001B[0m\r\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics\u001B[0m\r\n",
      "Plotting labels to runs/detect/train64/labels.jpg... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \r\n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\r\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\r\n",
      "Image sizes 640 train, 640 val\r\n",
      "Using 0 dataloader workers\r\n",
      "Logging results to \u001B[1mruns/detect/train64\u001B[0m\r\n",
      "Starting training for 10 epochs...\r\n",
      "Closing dataloader mosaic\r\n",
      "\r\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\r\n",
      "       1/10         0G          0          0          0        134        640:  ^C\r\n",
      "       1/10         0G          0          0          0        134        640:  \r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics-yolo/trainyolo.py\", line 31, in <module>\r\n",
      "    train(namespace.epochs,\r\n",
      "  File \"/Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics-yolo/trainyolo.py\", line 23, in train\r\n",
      "    results = model.train(data=\"./datasets/coco128.yaml\", epochs=int(epochs), imgsz=640, seed=0,\r\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py\", line 657, in train\r\n",
      "    self.trainer.train()\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py\", line 213, in train\r\n",
      "    self._do_train(world_size)\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py\", line 381, in _do_train\r\n",
      "    self.loss, self.loss_items = self.model(batch)\r\n",
      "                                 ^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py\", line 88, in forward\r\n",
      "    return self.loss(x, *args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py\", line 267, in loss\r\n",
      "    return self.criterion(preds, batch)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/ultralytics/utils/loss.py\", line 221, in __call__\r\n",
      "    _, target_bboxes, target_scores, fg_mask, _ = self.assigner(\r\n",
      "                                                  ^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\r\n",
      "    return self._call_impl(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\r\n",
      "    return forward_call(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\r\n",
      "    return func(*args, **kwargs)\r\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/ultralytics/utils/tal.py\", line 72, in forward\r\n",
      "    mask_pos, align_metric, overlaps = self.get_pos_mask(\r\n",
      "                                       ^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/ultralytics/utils/tal.py\", line 94, in get_pos_mask\r\n",
      "    align_metric, overlaps = self.get_box_metrics(pd_scores, pd_bboxes, gt_labels, gt_bboxes, mask_in_gts * mask_gt)\r\n",
      "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/ultralytics/utils/tal.py\", line 116, in get_box_metrics\r\n",
      "    pd_boxes = pd_bboxes.unsqueeze(1).expand(-1, self.n_max_boxes, -1, -1)[mask_gt]\r\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "  File \"/Users/khumachbayramova/anaconda3/lib/python3.11/site-packages/clearml/utilities/process/exit_hooks.py\", line 157, in signal_handler\r\n",
      "    return org_handler if not callable(org_handler) else org_handler(sig, frame)\r\n",
      "                                                         ^^^^^^^^^^^^^^^^^^^^^^^\r\n",
      "KeyboardInterrupt\r\n"
     ]
    }
   ],
   "source": [
    "!python trainyolo.py --epochs 10 --dfl 20 --box 0 --cls 0 --pose 0 --kobj 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T06:06:01.137843Z",
     "start_time": "2024-05-23T06:04:34.407081Z"
    }
   },
   "id": "e0cac2728f7ba69f",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5bd439ff2681896f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
