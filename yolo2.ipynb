{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-21T18:46:15.506785Z",
     "start_time": "2024-05-21T18:46:13.011500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (8.1.34)\r\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (3.7.2)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (4.7.0.72)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (9.4.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (6.0)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.31.0)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (1.11.1)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.2.1)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (0.17.1)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (4.65.0)\r\n",
      "Requirement already satisfied: psutil in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (5.9.0)\r\n",
      "Requirement already satisfied: py-cpuinfo in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (8.0.0)\r\n",
      "Requirement already satisfied: thop>=0.1.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (0.1.1.post2209072238)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (2.0.3)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from ultralytics) (0.12.2)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.0.5)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (0.10.0)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (4.25.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.4)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (1.23.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (23.1)\r\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\r\n",
      "Requirement already satisfied: filelock in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.9.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (1.11.1)\r\n",
      "Requirement already satisfied: networkx in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from torch>=1.8.0->ultralytics) (2023.4.0)\r\n",
      "Requirement already satisfied: six in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from cycler>=0.10->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.1)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: clearml in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (1.16.1)\r\n",
      "Requirement already satisfied: attrs>=18.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (23.2.0)\r\n",
      "Requirement already satisfied: furl>=2.0.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (2.1.3)\r\n",
      "Requirement already satisfied: jsonschema>=2.6.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (4.17.3)\r\n",
      "Requirement already satisfied: numpy>=1.10 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (1.23.5)\r\n",
      "Requirement already satisfied: pathlib2>=2.3.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (2.3.7.post1)\r\n",
      "Requirement already satisfied: Pillow>=4.1.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (9.4.0)\r\n",
      "Requirement already satisfied: psutil>=3.4.2 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (5.9.0)\r\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (3.0.9)\r\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (2.8.2)\r\n",
      "Requirement already satisfied: PyYAML>=3.12 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (6.0)\r\n",
      "Requirement already satisfied: requests>=2.20.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (2.31.0)\r\n",
      "Requirement already satisfied: six>=1.13.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (1.16.0)\r\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (1.26.16)\r\n",
      "Requirement already satisfied: pyjwt<2.9.0,>=2.4.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (2.4.0)\r\n",
      "Requirement already satisfied: referencing<0.40 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from clearml) (0.35.1)\r\n",
      "Requirement already satisfied: orderedmultidict>=1.0.1 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from furl>=2.0.0->clearml) (1.0.1)\r\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from jsonschema>=2.6.0->clearml) (0.18.0)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.0 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from referencing<0.40->clearml) (0.18.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from requests>=2.20.0->clearml) (2.0.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from requests>=2.20.0->clearml) (2.10)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/khumachbayramova/anaconda3/lib/python3.11/site-packages (from requests>=2.20.0->clearml) (2024.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install clearml"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T18:46:18.440523Z",
     "start_time": "2024-05-21T18:46:16.292413Z"
    }
   },
   "id": "9eaf2017c63e95a0",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import clearml\n",
    "clearml.browser_login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T21:01:49.727457Z",
     "start_time": "2024-05-21T21:01:47.973505Z"
    }
   },
   "id": "8af499f8b58e4118",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "Transferred 427/427 items from pretrained weights\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train18, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train18\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\n",
      "\n",
      "Transferred 427/427 items from pretrained weights\n",
      "ClearML Task: created new task id=0efc5af67edd411987a3849435812c9c\n",
      "2024-05-22 00:02:31,439 - clearml.Task - INFO - Storing jupyter notebook directly as code\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.util has been moved to tensorflow.python.checkpoint.checkpoint. The old module will be deleted in version 2.11.\n",
      "ClearML results page: https://app.clear.ml/projects/ab8891f06b194cd9b1ce30752b9ce999/experiments/0efc5af67edd411987a3849435812c9c/output/log\n",
      "ClearML Initialized a new task. If you want to run remotely, please add clearml-init and connect your arguments before initializing YOLO.\n",
      "ClearML Monitor: GPU monitoring failed getting GPU reading, switching off GPU monitoring\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train18', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics-yolo/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics-yolo/datasets/coco128/labels/val2017.cache... 41 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train18/labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mruns/detect/train18\u001B[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.081      1.117      1.142         66        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:03<00:00, 15.43s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.636      0.579       0.66      0.521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/10         0G      1.059      1.031      1.124         98        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:11<00:00, 16.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.534      0.615      0.648      0.515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/10         0G      1.073      1.068      1.122        111        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:12<00:00, 16.62s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.699      0.534      0.642      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/10         0G      1.047      0.942      1.145         98        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:07<00:00, 15.92s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.707      0.517      0.645      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/10         0G     0.9933     0.9576      1.084         52        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:05<00:00, 15.68s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:15<00:00,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.734      0.508      0.643      0.505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/10         0G     0.9892     0.9058      1.094         99        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:01<00:00, 15.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:15<00:00,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.744      0.493      0.636      0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/10         0G     0.9773     0.8787       1.07        188        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:03<00:00, 15.39s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:15<00:00,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.701      0.528      0.637      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/10         0G     0.9586     0.8698      1.058        147        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:05<00:00, 15.72s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:15<00:00,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.751      0.509      0.625      0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/10         0G      1.007     0.8701      1.105        100        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:11<00:00, 16.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.733      0.511       0.62      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/10         0G     0.9666      0.823      1.059        110        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:07<00:00, 16.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:16<00:00,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.767      0.492      0.616      0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10 epochs completed in 0.400 hours.\n",
      "Optimizer stripped from runs/detect/train18/weights/last.pt, 18.6MB\n",
      "Optimizer stripped from runs/detect/train18/weights/best.pt, 18.6MB\n",
      "\n",
      "Validating runs/detect/train18/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:14<00:00,  7.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.637       0.58       0.66      0.521\n",
      "                person         41         99      0.702      0.747      0.846      0.641\n",
      "               bicycle         41          2      0.414        0.5        0.5        0.4\n",
      "                   car         41         34      0.722      0.588      0.632      0.378\n",
      "            motorcycle         41          1      0.789          1      0.995      0.895\n",
      "                   bus         41          2      0.609          1      0.995      0.945\n",
      "                 train         41          2      0.402        0.5      0.745      0.497\n",
      "                 truck         41         10      0.623      0.334      0.531      0.359\n",
      "         traffic light         41          8      0.435      0.109      0.259     0.0597\n",
      "             stop sign         41          1      0.625          1      0.995      0.895\n",
      "                 bench         41          7      0.638      0.429      0.531      0.294\n",
      "                  bird         41         20      0.775       0.25      0.341      0.253\n",
      "                   cat         41          1          1          0      0.199      0.199\n",
      "                 horse         41          6          1      0.793       0.84      0.586\n",
      "                   cow         41          9      0.732      0.556      0.815      0.632\n",
      "                 zebra         41          5      0.781        0.6      0.769      0.692\n",
      "              backpack         41          1          1          0      0.166      0.116\n",
      "              umbrella         41          9      0.718      0.444      0.701      0.564\n",
      "               handbag         41          1       0.72          1      0.995      0.895\n",
      "                  kite         41          1      0.635          1      0.995      0.796\n",
      "          baseball bat         41          1      0.441          1      0.995      0.597\n",
      "        baseball glove         41          1      0.643          1      0.995      0.995\n",
      "            skateboard         41          3      0.684      0.735      0.913      0.633\n",
      "             surfboard         41          2       0.37      0.609      0.745      0.597\n",
      "         tennis racket         41          5      0.794      0.778       0.88      0.682\n",
      "                   cup         41          2       0.22          1      0.995       0.92\n",
      "                  fork         41          1          1          0      0.497      0.448\n",
      "                  bowl         41          3      0.641          1      0.995       0.82\n",
      "              sandwich         41          4          1      0.708      0.856      0.657\n",
      "              broccoli         41         12       0.26       0.25      0.201      0.135\n",
      "                carrot         41         13      0.425      0.119      0.174      0.106\n",
      "                 pizza         41         13          1      0.242      0.684      0.383\n",
      "                 chair         41         12      0.691      0.667      0.665      0.528\n",
      "                 couch         41          1      0.622          1      0.995      0.995\n",
      "          dining table         41          7      0.507      0.714      0.565      0.356\n",
      "                    tv         41          1      0.323          1      0.995      0.995\n",
      "                laptop         41          1          0          0      0.332      0.133\n",
      "            cell phone         41          7      0.393      0.143     0.0989     0.0455\n",
      "                  book         41         38      0.622      0.433      0.475      0.271\n",
      "                 clock         41          3      0.568      0.667       0.56      0.438\n",
      "              scissors         41          1          1          0          0          0\n",
      "            teddy bear         41          4      0.784          1      0.945      0.786\n",
      "            toothbrush         41          2      0.439      0.439      0.306      0.266\n",
      "Speed: 1.3ms preprocess, 349.8ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001B[1mruns/detect/train18\u001B[0m\n",
      "2024-05-22 00:27:10,563 - clearml.util - WARNING - 98 task found when searching for `{'include_archived': True}`\n",
      "2024-05-22 00:27:10,563 - clearml.util - WARNING - Selected task `train18` (id=0efc5af67edd411987a3849435812c9c)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<clearml.backend_api.session.callresult.CallResult at 0x326e43810>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T21:27:11.968135Z",
     "start_time": "2024-05-21T21:02:21.763613Z"
    }
   },
   "id": "5fa0cdb54186dfc1",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "Transferred 427/427 items from pretrained weights\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train20, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train20\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\n",
      "\n",
      "Transferred 427/427 items from pretrained weights\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train20', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics-yolo/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics-yolo/datasets/coco128/labels/val2017.cache... 41 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train20/labels.jpg... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mruns/detect/train20\u001B[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.088       1.17       1.21        278        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:03<00:00, 15.48s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:14<00:00,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.681       0.56      0.654      0.516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G        1.1      1.145      1.232        254        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:00<00:00, 15.05s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:15<00:00,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356       0.65      0.578      0.654      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.133      1.107      1.185        195        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [02:00<00:00, 15.04s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:15<00:00,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.652      0.578      0.656       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.116 hours.\n",
      "Optimizer stripped from runs/detect/train20/weights/last.pt, 18.6MB\n",
      "Optimizer stripped from runs/detect/train20/weights/best.pt, 18.6MB\n",
      "\n",
      "Validating runs/detect/train20/weights/best.pt...\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\n",
      "YOLOv5s summary (fused): 193 layers, 9142496 parameters, 0 gradients, 24.0 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:14<00:00,  7.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         41        356      0.681       0.56      0.654      0.516\n",
      "                person         41         99       0.74      0.727      0.849      0.636\n",
      "               bicycle         41          2      0.497        0.5      0.499       0.45\n",
      "                   car         41         34       0.74      0.529      0.665      0.386\n",
      "            motorcycle         41          1      0.771          1      0.995      0.895\n",
      "                   bus         41          2      0.627          1      0.995      0.945\n",
      "                 train         41          2      0.437        0.5      0.695      0.477\n",
      "                 truck         41         10      0.514        0.2      0.529      0.346\n",
      "         traffic light         41          8      0.361     0.0903      0.261     0.0699\n",
      "             stop sign         41          1      0.659          1      0.995      0.895\n",
      "                 bench         41          7      0.866      0.429      0.539      0.292\n",
      "                  bird         41         20       0.84      0.264       0.36      0.266\n",
      "                   cat         41          1          1          0      0.249      0.249\n",
      "                 horse         41          6          1      0.771       0.84      0.601\n",
      "                   cow         41          9      0.776      0.556      0.805      0.637\n",
      "                 zebra         41          5      0.809        0.6      0.678      0.642\n",
      "              backpack         41          1          1          0      0.124     0.0746\n",
      "              umbrella         41          9          1       0.44      0.721      0.551\n",
      "               handbag         41          1      0.893          1      0.995      0.895\n",
      "                  kite         41          1      0.695          1      0.995      0.796\n",
      "          baseball bat         41          1      0.452          1      0.995      0.597\n",
      "        baseball glove         41          1      0.678          1      0.995      0.995\n",
      "            skateboard         41          3      0.753      0.667      0.863        0.6\n",
      "             surfboard         41          2      0.495        0.5      0.745      0.597\n",
      "         tennis racket         41          5      0.788      0.754       0.88      0.677\n",
      "                   cup         41          2      0.245          1      0.995       0.92\n",
      "                  fork         41          1          1          0      0.497      0.448\n",
      "                  bowl         41          3      0.811          1      0.995      0.776\n",
      "              sandwich         41          4          1      0.678      0.845      0.636\n",
      "              broccoli         41         12      0.268       0.25      0.207      0.143\n",
      "                carrot         41         13      0.348     0.0835      0.173      0.104\n",
      "                 pizza         41         13          1      0.153      0.674      0.374\n",
      "                 chair         41         12      0.793      0.641      0.686      0.521\n",
      "                 couch         41          1       0.66          1      0.995      0.995\n",
      "          dining table         41          7      0.616       0.69      0.574      0.359\n",
      "                    tv         41          1      0.533          1      0.995      0.995\n",
      "                laptop         41          1          0          0      0.199     0.0796\n",
      "            cell phone         41          7      0.409      0.143     0.0991     0.0523\n",
      "                  book         41         38      0.675      0.273      0.466      0.263\n",
      "                 clock         41          3      0.622      0.667      0.561      0.439\n",
      "              scissors         41          1          1          0          0          0\n",
      "            teddy bear         41          4      0.799      0.993      0.945      0.735\n",
      "            toothbrush         41          2      0.426      0.426        0.3      0.262\n",
      "Speed: 1.4ms preprocess, 345.7ms inference, 0.0ms loss, 2.6ms postprocess per image\n",
      "Results saved to \u001B[1mruns/detect/train20\u001B[0m\n",
      "2024-05-22 01:09:40,737 - clearml.util - WARNING - 101 task found when searching for `{'include_archived': True}`\n",
      "2024-05-22 01:09:40,737 - clearml.util - WARNING - Selected task `train19` (id=53f44c1cf6f745458b0fb24fdaa40600)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<clearml.backend_api.session.callresult.CallResult at 0x3227b7050>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from clearml import Task\n",
    "from ultralytics import YOLO\n",
    "\n",
    "task = Task.create(project_name=\"–ò—Å–ò–ò\", task_name=\"baseline\")\n",
    "model_variant = \"yolov5s\"\n",
    "task.set_parameter(\"model_variant\", model_variant)\n",
    "\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "args=dict(data=\"./datasets/coco128.yaml\", epochs=3, imgsz=640, seed=0)\n",
    "task.connect(args)\n",
    "\n",
    "results = model.train(**args)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T22:09:41.837123Z",
     "start_time": "2024-05-21T22:02:09.016733Z"
    }
   },
   "id": "18f28deb5cf32f0e",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "Transferred 427/427 items from pretrained weights\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=10, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train22, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train22\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\n",
      "\n",
      "Transferred 427/427 items from pretrained weights\n",
      "WARNING ‚ö†Ô∏è ClearML installed but not initialized correctly, not logging this run. Task object can only be updated if created or in_progress [status=completed fields=['hyperparams']]\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train22', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics-yolo/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics-yolo/datasets/coco128/labels/val2017.cache... 41 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train22/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.005), 75 bias(decay=0.0)\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mruns/detect/train22\u001B[0m\n",
      "Starting training for 10 epochs...\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/10         0G      1.094       1.13      1.121        103        640:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6/8 [01:47<00:35, 17.99s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m model \u001B[38;5;241m=\u001B[39m YOLO(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myolov5s.yaml\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myolov5s.pt\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m results \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mtrain(data\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./datasets/coco128.yaml\u001B[39m\u001B[38;5;124m\"\u001B[39m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, imgsz\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m640\u001B[39m, seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.005\u001B[39m)\n\u001B[1;32m      8\u001B[0m Task\u001B[38;5;241m.\u001B[39mget_task()\u001B[38;5;241m.\u001B[39mmark_completed()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:657\u001B[0m, in \u001B[0;36mModel.train\u001B[0;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[1;32m    654\u001B[0m             \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mhub_session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession  \u001B[38;5;66;03m# attach optional HUB session\u001B[39;00m\n\u001B[0;32m--> 657\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m    658\u001B[0m \u001B[38;5;66;03m# Update model and cfg after training\u001B[39;00m\n\u001B[1;32m    659\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m):\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:213\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    210\u001B[0m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 213\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_train(world_size)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:389\u001B[0m, in \u001B[0;36mBaseTrainer._do_train\u001B[0;34m(self, world_size)\u001B[0m\n\u001B[1;32m    384\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    385\u001B[0m         (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss \u001B[38;5;241m*\u001B[39m i \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_items) \u001B[38;5;241m/\u001B[39m (i \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtloss \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_items\n\u001B[1;32m    386\u001B[0m     )\n\u001B[1;32m    388\u001B[0m \u001B[38;5;66;03m# Backward\u001B[39;00m\n\u001B[0;32m--> 389\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaler\u001B[38;5;241m.\u001B[39mscale(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss)\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m    391\u001B[0m \u001B[38;5;66;03m# Optimize - https://pytorch.org/docs/master/notes/amp_examples.html\u001B[39;00m\n\u001B[1;32m    392\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ni \u001B[38;5;241m-\u001B[39m last_opt_step \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maccumulate:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    523\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    524\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    267\u001B[0m     tensors,\n\u001B[1;32m    268\u001B[0m     grad_tensors_,\n\u001B[1;32m    269\u001B[0m     retain_graph,\n\u001B[1;32m    270\u001B[0m     create_graph,\n\u001B[1;32m    271\u001B[0m     inputs,\n\u001B[1;32m    272\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    273\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    274\u001B[0m )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, weight_decay=0.005)\n",
    "model.save()\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T06:45:20.228023Z",
     "start_time": "2024-05-22T06:43:25.700969Z"
    }
   },
   "id": "c2a5cd204eb346c9",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import clearml\n",
    "clearml.browser_login()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T06:46:54.139008Z",
     "start_time": "2024-05-22T06:46:53.144951Z"
    }
   },
   "id": "a1f3915aef6dcc",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-22 09:52:22,342 - clearml.util - WARNING - 101 task found when searching for `{'include_archived': True}`\n",
      "2024-05-22 09:52:22,342 - clearml.util - WARNING - Selected task `train19` (id=53f44c1cf6f745458b0fb24fdaa40600)\n"
     ]
    }
   ],
   "source": [
    "task.get_task().close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T06:52:22.864908Z",
     "start_time": "2024-05-22T06:52:21.668684Z"
    }
   },
   "id": "3c498404cc15acde",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP üí° Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "Transferred 427/427 items from pretrained weights\n",
      "New https://pypi.org/project/ultralytics/8.2.18 available üòÉ Update with 'pip install -U ultralytics'\n",
      "Ultralytics YOLOv8.1.34 üöÄ Python-3.11.5 torch-2.2.1 CPU (Apple M1 Pro)\n",
      "\u001B[34m\u001B[1mengine/trainer: \u001B[0mtask=detect, mode=train, model=yolov5s.yaml, data=./datasets/coco128.yaml, epochs=1, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train27, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.05, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train27\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      3520  ultralytics.nn.modules.conv.Conv             [3, 32, 6, 2, 2]              \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     18816  ultralytics.nn.modules.block.C3              [64, 64, 1]                   \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    115712  ultralytics.nn.modules.block.C3              [128, 128, 2]                 \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  3    625152  ultralytics.nn.modules.block.C3              [256, 256, 3]                 \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1]                 \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    131584  ultralytics.nn.modules.conv.Conv             [512, 256, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    361984  ultralytics.nn.modules.block.C3              [512, 256, 1, False]          \n",
      " 14                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 18                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 21                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1   1182720  ultralytics.nn.modules.block.C3              [512, 512, 1, False]          \n",
      " 24        [17, 20, 23]  1   2147008  ultralytics.nn.modules.head.Detect           [80, [128, 256, 512]]         \n",
      "YOLOv5s summary: 262 layers, 9153152 parameters, 9153136 gradients, 24.2 GFLOPs\n",
      "\n",
      "Transferred 427/427 items from pretrained weights\n",
      "WARNING ‚ö†Ô∏è ClearML installed but not initialized correctly, not logging this run. Task object can only be updated if created or in_progress [status=completed fields=['hyperparams']]\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mStart with 'tensorboard --logdir runs/detect/train27', view at http://localhost:6006/\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mtrain: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics-yolo/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 128/128 [00:00<?, ?it/s]\n",
      "\u001B[34m\u001B[1mval: \u001B[0mScanning /Users/khumachbayramova/Desktop/ITMO/–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞/–ò—Å–ò–ò/ultralytics-yolo/datasets/coco128/labels/val2017.cache... 41 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 41/41 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train27/labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1moptimizer:\u001B[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001B[34m\u001B[1moptimizer:\u001B[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.05), 75 bias(decay=0.0)\n",
      "\u001B[34m\u001B[1mTensorBoard: \u001B[0mmodel graph visualization added ‚úÖ\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001B[1mruns/detect/train27\u001B[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m task \u001B[38;5;241m=\u001B[39m Task\u001B[38;5;241m.\u001B[39mcreate(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest173\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m results \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mtrain(data\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./datasets/coco128.yaml\u001B[39m\u001B[38;5;124m\"\u001B[39m, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, imgsz\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m640\u001B[39m, seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.05\u001B[39m)\n\u001B[1;32m      8\u001B[0m task\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/model.py:657\u001B[0m, in \u001B[0;36mModel.train\u001B[0;34m(self, trainer, **kwargs)\u001B[0m\n\u001B[1;32m    654\u001B[0m             \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    656\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mhub_session \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msession  \u001B[38;5;66;03m# attach optional HUB session\u001B[39;00m\n\u001B[0;32m--> 657\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtrainer\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m    658\u001B[0m \u001B[38;5;66;03m# Update model and cfg after training\u001B[39;00m\n\u001B[1;32m    659\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m):\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:213\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    210\u001B[0m         ddp_cleanup(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28mstr\u001B[39m(file))\n\u001B[1;32m    212\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 213\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_train(world_size)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/engine/trainer.py:381\u001B[0m, in \u001B[0;36mBaseTrainer._do_train\u001B[0;34m(self, world_size)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mamp\u001B[38;5;241m.\u001B[39mautocast(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mamp):\n\u001B[1;32m    380\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess_batch(batch)\n\u001B[0;32m--> 381\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_items \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel(batch)\n\u001B[1;32m    382\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m RANK \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    383\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m=\u001B[39m world_size\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:88\u001B[0m, in \u001B[0;36mBaseModel.forward\u001B[0;34m(self, x, *args, **kwargs)\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;124;03mForward pass of the model on a single scale. Wrapper for `_forward_once` method.\u001B[39;00m\n\u001B[1;32m     80\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;124;03m    (torch.Tensor): The output of the network.\u001B[39;00m\n\u001B[1;32m     86\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mdict\u001B[39m):  \u001B[38;5;66;03m# for cases of training and validating while training.\u001B[39;00m\n\u001B[0;32m---> 88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m     89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:266\u001B[0m, in \u001B[0;36mBaseModel.loss\u001B[0;34m(self, batch, preds)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcriterion\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minit_criterion()\n\u001B[0;32m--> 266\u001B[0m preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforward(batch[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimg\u001B[39m\u001B[38;5;124m\"\u001B[39m]) \u001B[38;5;28;01mif\u001B[39;00m preds \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m preds\n\u001B[1;32m    267\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcriterion(preds, batch)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:89\u001B[0m, in \u001B[0;36mBaseModel.forward\u001B[0;34m(self, x, *args, **kwargs)\u001B[0m\n\u001B[1;32m     87\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mdict\u001B[39m):  \u001B[38;5;66;03m# for cases of training and validating while training.\u001B[39;00m\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredict(x, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:107\u001B[0m, in \u001B[0;36mBaseModel.predict\u001B[0;34m(self, x, profile, visualize, augment, embed)\u001B[0m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m augment:\n\u001B[1;32m    106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict_augment(x)\n\u001B[0;32m--> 107\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict_once(x, profile, visualize, embed)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/tasks.py:128\u001B[0m, in \u001B[0;36mBaseModel._predict_once\u001B[0;34m(self, x, profile, visualize, embed)\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m profile:\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_profile_one_layer(m, x, dt)\n\u001B[0;32m--> 128\u001B[0m x \u001B[38;5;241m=\u001B[39m m(x)  \u001B[38;5;66;03m# run\u001B[39;00m\n\u001B[1;32m    129\u001B[0m y\u001B[38;5;241m.\u001B[39mappend(x \u001B[38;5;28;01mif\u001B[39;00m m\u001B[38;5;241m.\u001B[39mi \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msave \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m)  \u001B[38;5;66;03m# save output\u001B[39;00m\n\u001B[1;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m visualize:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:255\u001B[0m, in \u001B[0;36mC3.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    254\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Forward pass through the CSP bottleneck with 2 convolutions.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 255\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv3(torch\u001B[38;5;241m.\u001B[39mcat((\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mm(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv1(x)), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv2(x)), \u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001B[0m, in \u001B[0;36mSequential.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[0;32m--> 217\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m module(\u001B[38;5;28minput\u001B[39m)\n\u001B[1;32m    218\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/modules/block.py:341\u001B[0m, in \u001B[0;36mBottleneck.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    339\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m    340\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"'forward()' applies the YOLO FPN to input data.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 341\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv1(x)) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madd \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv2(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcv1(x))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/ultralytics/nn/modules/conv.py:50\u001B[0m, in \u001B[0;36mConv.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     49\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Apply convolution, batch normalization and activation to input tensor.\"\"\"\u001B[39;00m\n\u001B[0;32m---> 50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mact(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbn(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv(x)))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1509\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1510\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1511\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1515\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1516\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1518\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1519\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1520\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1523\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:460\u001B[0m, in \u001B[0;36mConv2d.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    459\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 460\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_conv_forward(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mweight, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/conv.py:456\u001B[0m, in \u001B[0;36mConv2d._conv_forward\u001B[0;34m(self, input, weight, bias)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mzeros\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m    453\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(F\u001B[38;5;241m.\u001B[39mpad(\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reversed_padding_repeated_twice, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding_mode),\n\u001B[1;32m    454\u001B[0m                     weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    455\u001B[0m                     _pair(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n\u001B[0;32m--> 456\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m F\u001B[38;5;241m.\u001B[39mconv2d(\u001B[38;5;28minput\u001B[39m, weight, bias, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstride,\n\u001B[1;32m    457\u001B[0m                 \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpadding, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdilation, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgroups)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=1, imgsz=640, seed=0, weight_decay=0.05)\n",
    "Task.get_task().close()\n",
    "# Task.get_task().close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-22T06:53:45.394875Z",
     "start_time": "2024-05-22T06:53:32.599378Z"
    }
   },
   "id": "fb1e5a6fe685729a",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=1, imgsz=640, seed=0, weight_decay=0.5)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.024195Z"
    }
   },
   "id": "68784e01761fae65"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, weight_decay=0.8)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.025202Z"
    }
   },
   "id": "2a507de8539423e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, dfl=3)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.026152Z"
    }
   },
   "id": "5926fad90831e724"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, dfl=5)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.027188Z"
    }
   },
   "id": "6575026e56838a79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, dfl=8)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.028173Z"
    }
   },
   "id": "b3d5954eb5b903b0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, dfl=12)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.029096Z"
    }
   },
   "id": "c076d1ce07182081"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, kobj=3)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T22:32:39.041379Z",
     "start_time": "2024-05-21T22:32:39.030003Z"
    }
   },
   "id": "5429e84746fe5cc1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, kobj=7)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.030912Z"
    }
   },
   "id": "920aa50a12804d08"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, kobj=9)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.031951Z"
    }
   },
   "id": "4f302e99886bfefe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, pose=5)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.034578Z"
    }
   },
   "id": "f5c080a6a3dbff07"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, pose=10)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.035285Z"
    }
   },
   "id": "f1cb27be10f94b09"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, cls=2.5)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.035976Z"
    }
   },
   "id": "c479832aed5e877b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, cls=4)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.036585Z"
    }
   },
   "id": "1ba48b08ab360f19"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, cls=6)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.037059Z"
    }
   },
   "id": "9f3208520e5d9689"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, box=0.5)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.037526Z"
    }
   },
   "id": "af0b279f6828f977"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, box=2.5)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.037987Z"
    }
   },
   "id": "7dea85ad2f7dde2d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, box=5.5)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.038449Z"
    }
   },
   "id": "58b46c2e49bb01a2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, box=8)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.038954Z"
    }
   },
   "id": "953ff23f4d896651"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=10, imgsz=640, seed=0, box=11)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.039452Z"
    }
   },
   "id": "761ac487c801142e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from clearml import Task\n",
    "# Load a model\n",
    "model = YOLO(\"yolov5s.yaml\").load(\"yolov5s.pt\")\n",
    "\n",
    "# Train the model\n",
    "results = model.train(data=\"./datasets/coco128.yaml\", epochs=30, imgsz=640, seed=0)\n",
    "Task.get_task().mark_completed()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-21T22:32:39.039990Z"
    }
   },
   "id": "39879442293f73b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
